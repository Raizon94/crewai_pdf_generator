version: '3.8'

services:
  crewai-app:
    build: .
    ports:
      - "8501:8501"
    environment:
      - SERPER_API_KEY=${SERPER_API_KEY}
      - OLLAMA_HOST=host.docker.internal:11434
    volumes:
      - ./output:/app/output
      - ./temp:/app/temp
      - ./.env:/app/.env:ro
      # Montar código fuente para desarrollo (los cambios se reflejan sin rebuild)
      - ./tools:/app/tools
      - ./agents:/app/agents
      - ./flows:/app/flows
      - ./utils:/app/utils
      - ./app.py:/app/app.py
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    depends_on:
      - ollama-check
    networks:
      - crewai-network

  # Servicio para verificar que Ollama esté disponible
  ollama-check:
    image: curlimages/curl:latest
    command: >
      sh -c "
        echo 'Verificando conexión con Ollama...'
        until curl -f http://host.docker.internal:11434/api/tags; do
          echo 'Esperando a que Ollama esté disponible...'
          sleep 5
        done
        echo 'Ollama está disponible!'
      "
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - crewai-network

networks:
  crewai-network:
    driver: bridge
